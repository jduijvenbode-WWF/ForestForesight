% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/train_predict_raster.R
\name{train_predict_raster}
\alias{train_predict_raster}
\title{Train an XGBoost Model for ForestForesight}
\usage{
train_predict_raster(
  shape = NULL,
  country = NULL,
  prediction_date,
  ff_folder,
  train_start = NULL,
  train_end = NULL,
  save_path = NULL,
  trained_model = NULL,
  ff_prep_params = NULL,
  ff_train_params = NULL,
  threshold = 0.5,
  accuracy_csv = NA,
  overwrite = F,
  verbose = T
)
}
\arguments{
\item{verbose}{Boolean indicating whether to display training progress. Default is FALSE.}

\item{train_matrix}{An xgb.DMatrix object or a list containing 'features' and 'label' for training.}

\item{validation_matrix}{An xgb.DMatrix object or a list containing 'features' and 'label' for validation. Default is NA.}

\item{nrounds}{Number of boosting rounds. Default is 200.}

\item{eta}{Learning rate. Default is 0.1.}

\item{max_depth}{Maximum tree depth. Default is 5.}

\item{subsample}{Subsample ratio of the training instances. Default is 0.75.}

\item{eval_metric}{Evaluation metric. Default is "aucpr". Can be a custom evaluation metric.}

\item{early_stopping_rounds}{Number of rounds for early stopping. Default is 10.}

\item{num_class}{Number of classes for multi-class classification. Default is NULL.}

\item{gamma}{Minimum loss reduction required to make a further partition. Default is NULL.}

\item{maximize}{Boolean indicating whether to maximize the evaluation metric. Required for custom metrics.}

\item{min_child_weight}{Minimum sum of instance weight needed in a child. Default is 1.}

\item{xgb_model}{Previously trained model to continue training from. Can be an "xgb.Booster" object, raw data, or a file name. Default is NULL.}

\item{modelfilename}{String specifying where to save the model. Should end with ".model" extension.}

\item{features}{Vector of feature names used in the training dataset. Required when modelfilename is provided.}

\item{objective}{Learning objective. Default is "binary:logistic".}
}
\value{
A trained XGBoost model (xgb.Booster object).
}
\description{
This function trains an XGBoost model with optimized default parameters derived from worldwide data analysis.
}
\examples{
\dontrun{
# Prepare your data
train_data <- list(features = matrix(runif(1000), ncol = 10),
                   label = sample(0:1, 100, replace = TRUE))

# Train the model
model <- ff_train(train_matrix = train_data,
                  nrounds = 100,
                  eta = 0.05,
                  max_depth = 6,
                  modelfilename = "forest_model.model",
                  features = colnames(train_data$features))
}

}
\references{
Jonas van Duijvenbode (2023)
Zillah Calle (2023)
}
\seealso{
\code{\link{ff_prep}} for preparing data for this function
\code{\link{ff_predict}} for making predictions using the trained model
}
\keyword{forestry}
\keyword{machine-learning}
\keyword{xgboost}
